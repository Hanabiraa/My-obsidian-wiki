---
created: [" 07-04-2023 19:15"]
aliases: [Denoising diffusion probabilistic model]
tags:
- article/
---

# DDPM (Denoising diffusion probabilistic model)

## Тоже [[Diffusion models|Диффузионная модель]]

## Суть - введем больше уровней,  будет проходить одну цепочку (убирая шум или добавляя, смотря в какую сторону идем)

![[Pasted image 20230407191803.png]]

### Зашумление - Марковская цепь
- каждый уровень зашумления задается как нормальное распределение
- $\beta_t$ линейно возрастают
- Много раз последовательно сигнал из данных пропадает (так как накапливается сум и сам сигнал уходит в 0)
- Зашумление за несколько шагов - тут мы свернули все в одно зашумление


### Удаление шума - обратная во времени марковская цепь
![[Pasted image 20230407192352.png]]

#### Как обучать параметры $\theta$
- Максимизируя правдоподобие - распишем $p_{\theta}(x_0)$:
![[Pasted image 20230407192507.png]]
- Обуславливание на $x_0$ конкретно тут (сверху) не нужно, понадобиться далее


Распишем Правдоподобие ==> хотим получить **[[ELBO]]**:

![[Pasted image 20230407225548.png]]
1) (матожидание по настоящему распределению данных)
2) раскроем матожидание
3) внесем логарифм под второй интеграл => получили верзнюю оценку на минус правдоподобия => **будем минимизировать**
4) Объединили интеграл и заменили произведение на суммы:
![[Pasted image 20230407230205.png]]


5) Вынесем первое слагаемое для удобства (там внизу стоит $q(x_1|x_0)$) ==> теперь сумма по t > 1
6) распишем знаменатель (тут нам понадобился $x_0$) ТУТ ОШИБКА В ТРЕТЬЕЙ СТРОКЕ - там где мы домножаем на дробь, должно быть $\frac{q(x_{t-1}| x_0)}{q(x_t|x_0)}$
7) и таким образом многое взаимоуничтожится в знаменателе и в числителе в сумме
8) И таким образом получается сумма [[KL-Divergence]]

### ==> [[ELBO]]:
![[Pasted image 20230407230724.png]]

![[Pasted image 20230407230746.png]]
- Мы знаем как распределены переходы через несколько степов
- Поэтому можем все свернуть и получить параметры нормального распределения (с волной которые)

Распишем теперь [[KL-Divergence]] в сумме - это дивергенция двух нормальных распределений:
- $q_(x_{t-1}|x_t, x_0)$ - нормальное распределение
- $p_{\theta}(x_{t-1}|x_0)$ - нормальное распределение по определению
==> умеем считать KL-Divergence между двумя нормальными распределениями в явном виде

Зафиксириум матрицу ковариаций таким образом, чтобы там были сигмы таким образом, чтобы $\Sigma$ была дигональной и совпадала с матрицой ковариации для соответствующей $q$:
![[Pasted image 20230407231232.png]]

KL-Divergence с точностью до константы:
![[Pasted image 20230407231256.png]]

- У нас в обжективе написан квалрат разности мю с волной и мю-тета. Мы знаем как выглядит мю с волной, можно изначально параметризовать мю-тета, чтобы она была похожа изначально на мю с волной
- мы можем выразить $x_0$ и $x_t$
![[Pasted image 20230407231357.png]]

![[Pasted image 20230407231546.png]]

Перепишем так же мю-тета, параметризуем через $\epsilon$:
![[Pasted image 20230407231706.png]]

Во что преобразуется обжектив:
![[Pasted image 20230407231724.png]]

- Минимизируя это отношение, мы минимизируем верхнюю вариационную оценку

Параметризуя модель через $\epsilon_{\theta}$ (это какая-то нейросетка), результаты получаются лучше
