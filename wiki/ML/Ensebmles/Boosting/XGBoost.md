---
created:
  - " 13-11-2023 19:01"
aliases: 
tags:
  - article/
---

# XGBoost

##XGBoost
**Добавили инфу о вторых производных и регуляризатор**


### Пространство $\mathbf{R}^n$
При построении градиентног обустинга рассмотрим градиентный спуск в пространстве $\mathbf{R}^n$.

Соответствие обнозначений:

![[Pasted image 20231113184308.png]]

### Построение $b_t$
![[Pasted image 20231113184445.png]]
Распишем в терминаз пространства:


![[Pasted image 20231113184515.png]]

Почему задача логична? 
$s$ - предсказание предыдущей композиции, $\delta s$ - текущее то что добавляем
![[Pasted image 20231113184551.png]]

![[Pasted image 20231113184718.png]]
Задача оптимизации:
![[Pasted image 20231113184733.png]]

В обычном градиентном бустинге:
![[Pasted image 20231113184754.png]]

**Что сделали** - в бустинге считаем все вторые производные единицы (**аппроксимация второго порядка**), игнорируем кривизну функции потерь, в XGBoost - кажется что новая задача лучше приближает истинную функцию потерь


![[Pasted image 20231113184905.png]]

### Регуляризация

![[Pasted image 20231113185014.png]]

Введем регуляризаторы, штрафующие оба вида сложности:
![[Pasted image 20231113185138.png]]
Получили новую задачу оптимизации

### Как находить оптимальные ответы в листьях

Пусть дерево построено, найдем оптимальные ответы в листьях

![[Pasted image 20231113185458.png]]

Перепишем:
![[Pasted image 20231113185553.png]]

$G_k$ - сумма градиентов по объектам листа

Задача разбивается на $k$ независимых по листьям подзадач, оптимум:
![[Pasted image 20231113185743.png]]

Подставим и перепишем:
![[Pasted image 20231113185803.png]]

Новый $H(X_k)$ - критерий информативности

![[Pasted image 20231113190001.png]]
- тем самым выбираем структуру дерева исходя из минимизации исходной функции потерь



